{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c39416-b96e-461a-b396-c96eec6b91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook is for cleaning and preprocessing pond data\n",
    "Two labels will be added:\n",
    "    1-water safety score\n",
    "    2-Fish health score\n",
    "    These scores will be defined based on outliers identified in the data\n",
    "after all preprocessing all csvs will be concatenated and data shall be balanced for classification \n",
    "Different classification models shall be tested\n",
    "LSTM/RNN/GRU can be used for prediction because we are dealing with time series data\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "we compute the weight based on: \n",
    "High variability (coefficient of variation)\n",
    "High outlier frequency (many values outside IQR bounds)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Understand the code\n",
    "calculate fish health score\n",
    "concatenate dataframes\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "https://globalflyfisher.com/fish-better/fultons-condition-factor-calculator\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00446e1a-16ae-4d8f-8105-2cd70ba4a799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaout\\AppData\\Local\\Temp\\ipykernel_30176\\215217444.py:8: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pond4=pd.read_csv(\"Sensor_based_aquaponics_fish_pond_data/IoTpond4.csv\")\n",
      "C:\\Users\\kaout\\AppData\\Local\\Temp\\ipykernel_30176\\215217444.py:10: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pond7=pd.read_csv(\"Sensor_based_aquaponics_fish_pond_data/IoTPond7.csv\")\n",
      "C:\\Users\\kaout\\AppData\\Local\\Temp\\ipykernel_30176\\215217444.py:11: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pond8=pd.read_csv(\"Sensor_based_aquaponics_fish_pond_data/IoTpond8.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>Temperature (C)</th>\n",
       "      <th>Turbidity(NTU)</th>\n",
       "      <th>Dissolved Oxygen(g/ml)</th>\n",
       "      <th>PH</th>\n",
       "      <th>Ammonia(g/ml)</th>\n",
       "      <th>Nitrate(g/ml)</th>\n",
       "      <th>Population</th>\n",
       "      <th>Fish_Length(cm)</th>\n",
       "      <th>Fish_Weight(g)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-19 00:00:05 CET</td>\n",
       "      <td>1889</td>\n",
       "      <td>24.8750</td>\n",
       "      <td>100</td>\n",
       "      <td>4.505</td>\n",
       "      <td>8.43365</td>\n",
       "      <td>0.45842</td>\n",
       "      <td>193</td>\n",
       "      <td>50</td>\n",
       "      <td>7.11</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-19 00:01:02 CET</td>\n",
       "      <td>1890</td>\n",
       "      <td>24.9375</td>\n",
       "      <td>100</td>\n",
       "      <td>6.601</td>\n",
       "      <td>8.43818</td>\n",
       "      <td>0.45842</td>\n",
       "      <td>194</td>\n",
       "      <td>50</td>\n",
       "      <td>7.11</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-19 00:01:22 CET</td>\n",
       "      <td>1891</td>\n",
       "      <td>24.8750</td>\n",
       "      <td>100</td>\n",
       "      <td>15.797</td>\n",
       "      <td>8.42457</td>\n",
       "      <td>0.45842</td>\n",
       "      <td>192</td>\n",
       "      <td>50</td>\n",
       "      <td>7.11</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-19 00:01:44 CET</td>\n",
       "      <td>1892</td>\n",
       "      <td>24.9375</td>\n",
       "      <td>100</td>\n",
       "      <td>5.046</td>\n",
       "      <td>8.43365</td>\n",
       "      <td>0.45842</td>\n",
       "      <td>193</td>\n",
       "      <td>50</td>\n",
       "      <td>7.11</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-19 00:02:07 CET</td>\n",
       "      <td>1893</td>\n",
       "      <td>24.9375</td>\n",
       "      <td>100</td>\n",
       "      <td>38.407</td>\n",
       "      <td>8.40641</td>\n",
       "      <td>0.45842</td>\n",
       "      <td>192</td>\n",
       "      <td>50</td>\n",
       "      <td>7.11</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                created_at  entry_id  Temperature (C)  Turbidity(NTU)  \\\n",
       "0  2021-06-19 00:00:05 CET      1889          24.8750             100   \n",
       "1  2021-06-19 00:01:02 CET      1890          24.9375             100   \n",
       "2  2021-06-19 00:01:22 CET      1891          24.8750             100   \n",
       "3  2021-06-19 00:01:44 CET      1892          24.9375             100   \n",
       "4  2021-06-19 00:02:07 CET      1893          24.9375             100   \n",
       "\n",
       "   Dissolved Oxygen(g/ml)       PH  Ammonia(g/ml)  Nitrate(g/ml)  Population  \\\n",
       "0                   4.505  8.43365        0.45842            193          50   \n",
       "1                   6.601  8.43818        0.45842            194          50   \n",
       "2                  15.797  8.42457        0.45842            192          50   \n",
       "3                   5.046  8.43365        0.45842            193          50   \n",
       "4                  38.407  8.40641        0.45842            192          50   \n",
       "\n",
       "   Fish_Length(cm)  Fish_Weight(g)  \n",
       "0             7.11            2.91  \n",
       "1             7.11            2.91  \n",
       "2             7.11            2.91  \n",
       "3             7.11            2.91  \n",
       "4             7.11            2.91  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pond data for water condition\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pond1=pd.read_csv(\"Sensor_based_aquaponics_fish_pond_data/IoTpond1.csv\")\n",
    "pond2=pd.read_csv(\"Sensor_based_aquaponics_fish_pond_data/IoTpond2.csv\")\n",
    "pond3=pd.read_csv(\"Sensor_based_aquaponics_fish_pond_data/IoTpond3.csv\")\n",
    "pond4=pd.read_csv(\"Sensor_based_aquaponics_fish_pond_data/IoTpond4.csv\")\n",
    "pond6=pd.read_csv(\"Sensor_based_aquaponics_fish_pond_data/IoTpond6.csv\")\n",
    "pond7=pd.read_csv(\"Sensor_based_aquaponics_fish_pond_data/IoTPond7.csv\")\n",
    "pond8=pd.read_csv(\"Sensor_based_aquaponics_fish_pond_data/IoTpond8.csv\")\n",
    "pond9=pd.read_csv(\"Sensor_based_aquaponics_fish_pond_data/IoTpond9.csv\")\n",
    "pond10=pd.read_csv(\"Sensor_based_aquaponics_fish_pond_data/IoTpond10.csv\")\n",
    "pond11=pd.read_csv(\"Sensor_based_aquaponics_fish_pond_data/IoTpond11.csv\")\n",
    "pond12=pd.read_csv(\"Sensor_based_aquaponics_fish_pond_data/IoTpond12.csv\")\n",
    "\n",
    "pond1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "27843da1-ac58-49da-b5cc-6fe0488377bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data columns:\n",
      "Index(['created_at', 'entry_id', 'TEMPERATURE', 'TURBIDITY', 'DISOLVED OXYGEN',\n",
      "       'pH', 'AMMONIA', 'NITRATE', 'Population', 'Length', 'Weight'],\n",
      "      dtype='object')\n",
      "\n",
      "Data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3590 entries, 0 to 3589\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   created_at       3590 non-null   object \n",
      " 1   entry_id         3590 non-null   int64  \n",
      " 2   TEMPERATURE      3590 non-null   float64\n",
      " 3   TURBIDITY        3590 non-null   int64  \n",
      " 4   DISOLVED OXYGEN  3590 non-null   float64\n",
      " 5   pH               3590 non-null   float64\n",
      " 6   AMMONIA          3590 non-null   float64\n",
      " 7   NITRATE          3590 non-null   int64  \n",
      " 8   Population       3590 non-null   int64  \n",
      " 9   Length           3590 non-null   float64\n",
      " 10  Weight           3590 non-null   float64\n",
      "dtypes: float64(6), int64(4), object(1)\n",
      "memory usage: 308.6+ KB\n",
      "None\n",
      "\n",
      "Data shape:\n",
      "(3590, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data columns:\")\n",
    "print(pond12.columns)\n",
    "print(\"\\nData info:\")\n",
    "print(pond12.info())\n",
    "print(\"\\nData shape:\")\n",
    "print(pond12.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c11df555-156f-4365-9ace-dbf3a57d7e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pond7 contains additional empty columns to drop\n",
    "pond7=pond7.drop(columns=[\"Unnamed: 11\",\"Unnamed: 12\",\"Unnamed: 13\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "761f3965-98e1-43b7-86a3-491a12ebc443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 169078 entries, 0 to 169184\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   created_at              169078 non-null  object \n",
      " 1   entry_id                169078 non-null  int64  \n",
      " 2   Temperature(C)          169078 non-null  float64\n",
      " 3   Turbidity(NTU)          169078 non-null  int64  \n",
      " 4   Dissolved Oxygen(g/ml)  169078 non-null  float64\n",
      " 5   PH                      169078 non-null  float64\n",
      " 6   Ammonia(g/ml)           169078 non-null  float64\n",
      " 7   Nitrate(g/ml)           169078 non-null  int64  \n",
      " 8   Population              169078 non-null  int64  \n",
      " 9   Fish_Length(cm)         169078 non-null  float64\n",
      " 10  Fish_Weight(g)          169078 non-null  float64\n",
      "dtypes: float64(6), int64(4), object(1)\n",
      "memory usage: 15.5+ MB\n"
     ]
    }
   ],
   "source": [
    "pond3=pond3.dropna()\n",
    "pond3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "706f4c87-19ce-4cca-9ece-c4975e39216d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 169078 rows, 11 columns\n",
      "\n",
      "======================================================================\n",
      "DATA-DRIVEN SAFETY RANGES (IQR METHOD)\n",
      "======================================================================\n",
      "Parameters found: 6\n",
      "Total rows: 169078\n",
      "\n",
      "✓ Temperature(C):\n",
      "  Data points: 169078\n",
      "  Optimal:    23.375 - 24.125\n",
      "  Acceptable: 23.000 - 24.500\n",
      "  Critical:   < 22.250 or > 25.250\n",
      "  Weight:     0.0327 (3.27%)\n",
      "\n",
      "✓ Dissolved Oxygen(g/ml):\n",
      "  Data points: 169078\n",
      "  Optimal:    5.080 - 8.088\n",
      "  Acceptable: 3.576 - 9.592\n",
      "  Critical:   < 0.568 or > 12.600\n",
      "  Weight:     0.3885 (38.85%)\n",
      "\n",
      "✓ PH:\n",
      "  Data points: 169078\n",
      "  Optimal:    7.244 - 7.344\n",
      "  Acceptable: 7.194 - 7.394\n",
      "  Critical:   < 7.095 or > 7.494\n",
      "  Weight:     0.0805 (8.05%)\n",
      "\n",
      "✓ Ammonia(g/ml):\n",
      "  Data points: 169078\n",
      "  Optimal:    5.759 - 1009.766\n",
      "  Acceptable: -496.245 - 1511.770\n",
      "  Critical:   < -1500.252 or > 2515.777\n",
      "  Weight:     0.0616 (6.16%)\n",
      "\n",
      "✓ Turbidity(NTU):\n",
      "  Data points: 169078\n",
      "  Optimal:    80.000 - 100.000\n",
      "  Acceptable: 70.000 - 110.000\n",
      "  Critical:   < 50.000 or > 130.000\n",
      "  Weight:     0.1689 (16.89%)\n",
      "\n",
      "✓ Nitrate(g/ml):\n",
      "  Data points: 169078\n",
      "  Optimal:    123.000 - 585.000\n",
      "  Acceptable: -108.000 - 816.000\n",
      "  Critical:   < -570.000 or > 1278.000\n",
      "  Weight:     0.2678 (26.78%)\n",
      "\n",
      "======================================================================\n",
      "Successfully generated ranges for 6 parameters\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaout\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_iqr_ranges(df, param_name):\n",
    "    data = df[param_name].dropna()\n",
    "    # Calculate quartiles and IQR\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q2 = data.quantile(0.50)  # Median\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Calculate outlier boundaries\n",
    "    lower_outlier = Q1 - 1.5 * IQR\n",
    "    upper_outlier = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Define ranges\n",
    "    ranges = {\n",
    "        'optimal': (Q1, Q3),              # Middle 50% (IQR itself)\n",
    "        'acceptable': (Q1 - 0.5*IQR, Q3 + 0.5*IQR),  # Slightly extended\n",
    "        'critical_low': lower_outlier,     # Below this = outlier\n",
    "        'critical_high': upper_outlier,    # Above this = outlier\n",
    "        'Q1': Q1,\n",
    "        'Q2': Q2,\n",
    "        'Q3': Q3,\n",
    "        'IQR': IQR\n",
    "    }\n",
    "    return ranges\n",
    "\n",
    "\n",
    "def calculate_parameter_weights(df, param_list):\n",
    "    weights = {}\n",
    "    \n",
    "    for param in param_list:\n",
    "        data = df[param].dropna()\n",
    "        if len(data) < 3:\n",
    "            weights[param] = 0\n",
    "            print(f\"  {param}: Insufficient data, setting weight to 0\")\n",
    "            continue\n",
    "        \n",
    "        mean = data.mean()\n",
    "        std = data.std()\n",
    "        \n",
    "        if pd.isna(mean) or pd.isna(std):\n",
    "            cv = 0\n",
    "        elif abs(mean) < 1e-10:  # Mean too close to zero\n",
    "            cv = std  # Use std directly instead of CV\n",
    "        else:\n",
    "            cv = abs(std / mean)  # Use absolute value to handle negative means\n",
    "        \n",
    "        # Replace inf or nan with 0\n",
    "        if not np.isfinite(cv):\n",
    "            cv = 0\n",
    "        \n",
    "        # Calculate outlier percentage\n",
    "        Q1 = data.quantile(0.25)\n",
    "        Q3 = data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        if IQR == 0:\n",
    "            outlier_pct = 0\n",
    "        else:\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            outlier_pct = ((data < lower_bound).sum() + (data > upper_bound).sum()) / len(data)\n",
    "        \n",
    "        # Combined score: 60% CV + 40% outlier frequency\n",
    "        combined_score = 0.6 * cv + 0.4 * outlier_pct\n",
    "        \n",
    "        # Final safety check\n",
    "        if not np.isfinite(combined_score):\n",
    "            combined_score = 0\n",
    "        \n",
    "        weights[param] = combined_score\n",
    "    \n",
    "    # Normalize weights to sum to 1.0\n",
    "    total_weight = sum(weights.values())\n",
    "    \n",
    "    if total_weight == 0 or not np.isfinite(total_weight):\n",
    "        weights = {k: 1.0/len(param_list) for k in param_list}\n",
    "    else:\n",
    "        weights = {k: v/total_weight for k, v in weights.items()}\n",
    "    \n",
    "    return weights\n",
    "\n",
    "\n",
    "def build_safety_ranges_from_data(df, manual_overrides=None):\n",
    "    # Define parameters to analyze\n",
    "    param_list = [\n",
    "        'Temperature(C)',\n",
    "        'Dissolved Oxygen(g/ml)',\n",
    "        'PH',\n",
    "        'Ammonia(g/ml)',\n",
    "        'Turbidity(NTU)',\n",
    "        'Nitrate(g/ml)'\n",
    "    ]\n",
    "    # Filter to existing columns\n",
    "    param_list = [p for p in param_list if p in df.columns]\n",
    "    \n",
    "    if not param_list:\n",
    "        print(\"ERROR: No valid water quality parameters found in dataframe!\")\n",
    "        print(f\"Available columns: {df.columns.tolist()}\")\n",
    "        return {}\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DATA-DRIVEN SAFETY RANGES (IQR METHOD)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Parameters found: {len(param_list)}\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    \n",
    "    # Calculate weights\n",
    "    weights = calculate_parameter_weights(df, param_list)\n",
    "    \n",
    "    # Build ranges dictionary\n",
    "    SAFETY_RANGES = {}\n",
    "    \n",
    "    for param in param_list:\n",
    "        try:\n",
    "            # Check if parameter has enough valid data\n",
    "            valid_data = df[param].dropna()\n",
    "            if len(valid_data) < 3:\n",
    "                print(f\"\\n {param}: Insufficient data ({len(valid_data)} values), skipping...\")\n",
    "                continue\n",
    "            \n",
    "            ranges = calculate_iqr_ranges(df, param)\n",
    "            \n",
    "            # Validate ranges (check for NaN or infinite values)\n",
    "            if not all(np.isfinite([ranges['optimal'][0], ranges['optimal'][1], \n",
    "                                   ranges['acceptable'][0], ranges['acceptable'][1],\n",
    "                                   ranges['critical_low'], ranges['critical_high']])):\n",
    "                print(f\"\\n {param}: Invalid ranges detected, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # Apply manual overrides if provided\n",
    "            if manual_overrides and param in manual_overrides:\n",
    "                print(f\"\\n{param}: Applying manual overrides\")\n",
    "                ranges.update(manual_overrides[param])\n",
    "            \n",
    "            SAFETY_RANGES[param] = {\n",
    "                'optimal': ranges['optimal'],\n",
    "                'acceptable': ranges['acceptable'],\n",
    "                'critical_low': ranges['critical_low'],\n",
    "                'critical_high': ranges['critical_high'],\n",
    "                'weight': weights[param]\n",
    "            }\n",
    "            \n",
    "            # Print summary\n",
    "            print(f\"\\n✓ {param}:\")\n",
    "            print(f\"  Data points: {len(valid_data)}\")\n",
    "            print(f\"  Optimal:    {ranges['optimal'][0]:.3f} - {ranges['optimal'][1]:.3f}\")\n",
    "            print(f\"  Acceptable: {ranges['acceptable'][0]:.3f} - {ranges['acceptable'][1]:.3f}\")\n",
    "            print(f\"  Critical:   < {ranges['critical_low']:.3f} or > {ranges['critical_high']:.3f}\")\n",
    "            print(f\"  Weight:     {weights[param]:.4f} ({weights[param]*100:.2f}%)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n ERROR processing {param}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Successfully generated ranges for {len(SAFETY_RANGES)} parameters\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if not SAFETY_RANGES:\n",
    "        print(\"\\n WARNING: No safety ranges were generated!\")\n",
    "        print(\"Possible reasons:\")\n",
    "        print(\"  - Insufficient data in all columns\")\n",
    "        print(\"  - All values are NaN\")\n",
    "        print(\"  - Column names don't match expected parameter names\")\n",
    "    \n",
    "    return SAFETY_RANGES\n",
    "\n",
    "\n",
    "def export_ranges_to_file(SAFETY_RANGES, filename='safety_ranges.py'):\n",
    "    \"\"\"\n",
    "    Export ranges as a Python file\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"# Auto-generated safety ranges using IQR method\\n\\n\")\n",
    "        f.write(\"SAFETY_RANGES = {\\n\")\n",
    "        \n",
    "        for param, ranges in SAFETY_RANGES.items():\n",
    "            f.write(f\"    '{param}': {{\\n\")\n",
    "            f.write(f\"        'optimal': ({ranges['optimal'][0]:.4f}, {ranges['optimal'][1]:.4f}),\\n\")\n",
    "            f.write(f\"        'acceptable': ({ranges['acceptable'][0]:.4f}, {ranges['acceptable'][1]:.4f}),\\n\")\n",
    "            f.write(f\"        'critical_low': {ranges['critical_low']:.4f},\\n\")\n",
    "            f.write(f\"        'critical_high': {ranges['critical_high']:.4f},\\n\")\n",
    "            f.write(f\"        'weight': {ranges['weight']:.4f}\\n\")\n",
    "            f.write(f\"    }},\\n\")\n",
    "        \n",
    "        f.write(\"}\\n\")\n",
    "    \n",
    "    print(f\"\\n✓ Safety ranges exported to: {filename}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pond3.copy()\n",
    "    print(f\"Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    SAFETY_RANGES = build_safety_ranges_from_data(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bb2e2e06-b2f9-46c9-bd36-0da8734c5fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Calculated: Temperature(C)_Safety_Score\n",
      "✓ Calculated: Dissolved Oxygen(g/ml)_Safety_Score\n",
      "✓ Calculated: PH_Safety_Score\n",
      "✓ Calculated: Ammonia(g/ml)_Safety_Score\n",
      "✓ Calculated: Turbidity(NTU)_Safety_Score\n",
      "✓ Calculated: Nitrate(g/ml)_Safety_Score\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_parameter_score(value, param_name):\n",
    "    if param_name not in SAFETY_RANGES:\n",
    "        return np.nan\n",
    "    \n",
    "    ranges = SAFETY_RANGES[param_name]\n",
    "    opt_low, opt_high = ranges['optimal']\n",
    "    acc_low, acc_high = ranges['acceptable']\n",
    "    crit_low = ranges['critical_low']\n",
    "    crit_high = ranges['critical_high']\n",
    "    \n",
    "    # Handle NaN values\n",
    "    if pd.isna(value):\n",
    "        return 0\n",
    "    # OPTIMAL RANGE = 100 points\n",
    "    if opt_low <= value <= opt_high:\n",
    "        return 100\n",
    "    \n",
    "    # ACCEPTABLE RANGE = 75-99 points (linear interpolation)\n",
    "    elif acc_low <= value < opt_low:\n",
    "        # Between acceptable_low and optimal_low\n",
    "        score = 75 + 25 * (value - acc_low) / (opt_low - acc_low)\n",
    "        return score\n",
    "    \n",
    "    elif opt_high < value <= acc_high:\n",
    "        # Between optimal_high and acceptable_high\n",
    "        score = 75 + 25 * (acc_high - value) / (acc_high - opt_high)\n",
    "        return score\n",
    "    \n",
    "    # WARNING ZONE = 25-74 points\n",
    "    elif crit_low < value < acc_low:\n",
    "        # Between critical_low and acceptable_low\n",
    "        score = 25 + 50 * (value - crit_low) / (acc_low - crit_low)\n",
    "        return score\n",
    "    \n",
    "    elif acc_high < value < crit_high:\n",
    "        # Between acceptable_high and critical_high\n",
    "        score = 25 + 50 * (crit_high - value) / (crit_high - acc_high)\n",
    "        return score\n",
    "    \n",
    "    # CRITICAL ZONE = 0-24 points\n",
    "    else:\n",
    "        # Beyond critical thresholds\n",
    "        if value <= crit_low:\n",
    "            # Extremely low\n",
    "            return max(0, 24 * (value / crit_low)) if crit_low > 0 else 0\n",
    "        else:\n",
    "            # Extremely high\n",
    "            excess_ratio = (value - crit_high) / crit_high if crit_high > 0 else 1\n",
    "            return max(0, 24 * (1 / (1 + excess_ratio)))\n",
    "\n",
    "\n",
    "def add_safety_scores(df):\n",
    "    # Calculate individual parameter scores\n",
    "    for param in SAFETY_RANGES.keys():\n",
    "        if param in df.columns:\n",
    "            score_col = f'{param}_Safety_Score'\n",
    "            df[score_col] = df[param].apply(lambda x: calculate_parameter_score(x, param))\n",
    "            print(f\"✓ Calculated: {score_col}\")\n",
    "    \n",
    "    # Calculate overall weighted safety score\n",
    "    df['Water_Safety_Score'] = 0\n",
    "    total_weight = 0\n",
    "    \n",
    "    for param, ranges in SAFETY_RANGES.items():\n",
    "        if param in df.columns:\n",
    "            score_col = f'{param}_Safety_Score'\n",
    "            weight = ranges['weight']\n",
    "            df['Water_Safety_Score'] += df[score_col] * weight\n",
    "            total_weight += weight\n",
    "    \n",
    "    # Normalize if weights don't sum to 1.0\n",
    "    if total_weight != 1.0:\n",
    "        df['Water_Safety_Score'] = df['Water_Safety_Score'] / total_weight\n",
    "        \n",
    "    # Add safety category\n",
    "    def get_safety_category(score):\n",
    "        if score >= 75:\n",
    "            return 'SAFE'\n",
    "        elif score >= 50:\n",
    "            return 'WARNING'\n",
    "        elif score >= 25:\n",
    "            return 'DANGER'\n",
    "        else:\n",
    "            return 'CRITICAL'\n",
    "    \n",
    "    df['Safety_Category'] = df['Water_Safety_Score'].apply(get_safety_category)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pond3.copy()    \n",
    "    df = add_safety_scores(df)\n",
    "    output_file = 'pond3_with_safety_scores.csv'\n",
    "    df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f2392210-7a81-4b46-b385-2d031c52a40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Safety_Category\n",
       "SAFE       119372\n",
       "WARNING     46388\n",
       "DANGER       3318\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"pond3_with_safety_scores.csv\")\n",
    "data[\"Safety_Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97e44012-e2c9-483c-bc53-508fa639000e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaout\\AppData\\Local\\Temp\\ipykernel_40140\\2991685805.py:6: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df4=pd.read_csv(\"pond4_with_safety_scores.csv\")\n",
      "C:\\Users\\kaout\\AppData\\Local\\Temp\\ipykernel_40140\\2991685805.py:8: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df7=pd.read_csv(\"pond7_with_safety_scores.csv\")\n",
      "C:\\Users\\kaout\\AppData\\Local\\Temp\\ipykernel_40140\\2991685805.py:9: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8=pd.read_csv(\"pond8_with_safety_scores.csv\")\n"
     ]
    }
   ],
   "source": [
    "#concatenating dataframes\n",
    "import pandas as pd\n",
    "df1=pd.read_csv(\"pond1_with_safety_scores.csv\")\n",
    "df2=pd.read_csv(\"pond2_with_safety_scores.csv\")\n",
    "df3=pd.read_csv(\"pond3_with_safety_scores.csv\")\n",
    "df4=pd.read_csv(\"pond4_with_safety_scores.csv\")\n",
    "df6=pd.read_csv(\"pond6_with_safety_scores.csv\")\n",
    "df7=pd.read_csv(\"pond7_with_safety_scores.csv\")\n",
    "df8=pd.read_csv(\"pond8_with_safety_scores.csv\")\n",
    "df9=pd.read_csv(\"pond9_with_safety_scores.csv\")\n",
    "df10=pd.read_csv(\"pond10_with_safety_scores.csv\")\n",
    "df11=pd.read_csv(\"pond11_with_safety_scores.csv\")\n",
    "df12=pd.read_csv(\"pond12_with_safety_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e8c5faa-24bb-48aa-9454-e6139d5e16f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STANDARDIZING AND CONCATENATING DATAFRAMES\n",
      "======================================================================\n",
      "\n",
      "Processing DataFrame 1:\n",
      "  Original shape: (83072, 19)\n",
      "  Original columns: 19\n",
      "  Standardized shape: (83072, 13)\n",
      "  Standardized columns: ['timestamp', 'entry_id', 'temperature', 'turbidity', 'dissolved_oxygen', 'ph', 'ammonia', 'nitrate', 'population', 'fish_length', 'fish_weight', 'water_safety_score', 'safety_category']\n",
      "\n",
      "Processing DataFrame 2:\n",
      "  Original shape: (172249, 18)\n",
      "  Original columns: 18\n",
      "  Standardized shape: (172249, 13)\n",
      "  Standardized columns: ['timestamp', 'entry_id', 'temperature', 'turbidity', 'dissolved_oxygen', 'ph', 'ammonia', 'nitrate', 'population', 'fish_length', 'fish_weight', 'water_safety_score', 'safety_category']\n",
      "\n",
      "Processing DataFrame 3:\n",
      "  Original shape: (169078, 19)\n",
      "  Original columns: 19\n",
      "  Standardized shape: (169078, 13)\n",
      "  Standardized columns: ['timestamp', 'entry_id', 'temperature', 'turbidity', 'dissolved_oxygen', 'ph', 'ammonia', 'nitrate', 'population', 'fish_length', 'fish_weight', 'water_safety_score', 'safety_category']\n",
      "\n",
      "Processing DataFrame 4:\n",
      "  Original shape: (89742, 18)\n",
      "  Original columns: 18\n",
      "  Standardized shape: (89742, 13)\n",
      "  Standardized columns: ['timestamp', 'entry_id', 'temperature', 'turbidity', 'dissolved_oxygen', 'ph', 'ammonia', 'nitrate', 'population', 'fish_length', 'fish_weight', 'water_safety_score', 'safety_category']\n",
      "\n",
      "Processing DataFrame 5:\n",
      "  Original shape: (151785, 18)\n",
      "  Original columns: 18\n",
      "  Standardized shape: (151785, 12)\n",
      "  Standardized columns: ['timestamp', 'entry_id', 'temperature', 'turbidity', 'dissolved_oxygen', 'ph', 'ammonia', 'nitrate', 'fish_length', 'fish_weight', 'water_safety_score', 'safety_category']\n",
      "\n",
      "Processing DataFrame 6:\n",
      "  Original shape: (620, 19)\n",
      "  Original columns: 19\n",
      "  Standardized shape: (620, 13)\n",
      "  Standardized columns: ['timestamp', 'entry_id', 'temperature', 'turbidity', 'dissolved_oxygen', 'ph', 'ammonia', 'nitrate', 'population', 'fish_length', 'fish_weight', 'water_safety_score', 'safety_category']\n",
      "\n",
      "Processing DataFrame 7:\n",
      "  Original shape: (3164, 19)\n",
      "  Original columns: 19\n",
      "  Standardized shape: (3164, 13)\n",
      "  Standardized columns: ['timestamp', 'entry_id', 'temperature', 'turbidity', 'dissolved_oxygen', 'ph', 'ammonia', 'nitrate', 'population', 'fish_length', 'fish_weight', 'water_safety_score', 'safety_category']\n",
      "\n",
      "Processing DataFrame 8:\n",
      "  Original shape: (3590, 19)\n",
      "  Original columns: 19\n",
      "  Standardized shape: (3590, 13)\n",
      "  Standardized columns: ['timestamp', 'entry_id', 'temperature', 'turbidity', 'dissolved_oxygen', 'ph', 'ammonia', 'nitrate', 'population', 'fish_length', 'fish_weight', 'water_safety_score', 'safety_category']\n",
      "\n",
      "Processing DataFrame 9:\n",
      "  Original shape: (91015, 18)\n",
      "  Original columns: 18\n",
      "  Standardized shape: (91015, 13)\n",
      "  Standardized columns: ['timestamp', 'entry_id', 'temperature', 'turbidity', 'dissolved_oxygen', 'ph', 'ammonia', 'nitrate', 'population', 'fish_length', 'fish_weight', 'water_safety_score', 'safety_category']\n",
      "\n",
      "======================================================================\n",
      "CONCATENATION COMPLETE\n",
      "======================================================================\n",
      "Combined shape: (764315, 14)\n",
      "Total rows: 764315\n",
      "Columns: ['timestamp', 'entry_id', 'temperature', 'turbidity', 'dissolved_oxygen', 'ph', 'ammonia', 'nitrate', 'population', 'fish_length', 'fish_weight', 'water_safety_score', 'safety_category', 'source_df']\n",
      "\n",
      "Rows per source:\n",
      "source_df\n",
      "1     83072\n",
      "2    172249\n",
      "3    169078\n",
      "4     89742\n",
      "5    151785\n",
      "6       620\n",
      "7      3164\n",
      "8      3590\n",
      "9     91015\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values per column:\n",
      "  ammonia: 90 (0.01%)\n",
      "  population: 151785 (19.86%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def standardize_dataframe(df):\n",
    "    # Create comprehensive column mapping\n",
    "    column_mapping = {\n",
    "        # Timestamp columns\n",
    "        'created_at': 'timestamp',\n",
    "        'Date': 'timestamp',\n",
    "        'DATE': 'timestamp',\n",
    "        \n",
    "        # Entry ID\n",
    "        'entry_id': 'entry_id',\n",
    "        \n",
    "        # Temperature variations\n",
    "        'Temperature (C)': 'temperature',\n",
    "        'Temperature(C)': 'temperature',\n",
    "        'TEMPERATURE': 'temperature',\n",
    "        \n",
    "        # Turbidity variations\n",
    "        'Turbidity(NTU)': 'turbidity',\n",
    "        'Turbidity (NTU)': 'turbidity',\n",
    "        'TURBIDITY': 'turbidity',\n",
    "        \n",
    "        # Dissolved Oxygen variations\n",
    "        'Dissolved Oxygen(g/ml)': 'dissolved_oxygen',\n",
    "        'Dissolved Oxygen (mg/L)': 'dissolved_oxygen',\n",
    "        'DISOLVED OXYGEN': 'dissolved_oxygen',\n",
    "        \n",
    "        # pH variations\n",
    "        'PH': 'ph',\n",
    "        'pH': 'ph',\n",
    "        \n",
    "        # Ammonia variations\n",
    "        'Ammonia(g/ml)': 'ammonia',\n",
    "        'Ammonia (mg/L)': 'ammonia',\n",
    "        'AMMONIA': 'ammonia',\n",
    "        \n",
    "        # Nitrate variations\n",
    "        'Nitrate(g/ml)': 'nitrate',\n",
    "        'Nitrate (mg/L)': 'nitrate',\n",
    "        'NITRATE': 'nitrate',\n",
    "        \n",
    "        # Population\n",
    "        'Population': 'population',\n",
    "        \n",
    "        # Fish Length variations\n",
    "        'Fish_Length(cm)': 'fish_length',\n",
    "        'Fish_Length (cm)': 'fish_length',\n",
    "        'Fish_length(cm)': 'fish_length',\n",
    "        'Total_length (cm)': 'fish_length',\n",
    "        'Length': 'fish_length',\n",
    "        'Lenght': 'fish_length',\n",
    "        \n",
    "        # Fish Weight variations\n",
    "        'Fish_Weight(g)': 'fish_weight',\n",
    "        'Fish_Weight (g)': 'fish_weight',\n",
    "        'Fish_weight(g)': 'fish_weight',\n",
    "        'Weight (g)': 'fish_weight',\n",
    "        'Weight': 'fish_weight',\n",
    "        \n",
    "        # Safety scores to keep\n",
    "        'Water_Safety_Score': 'water_safety_score',\n",
    "        'Safety_Category': 'safety_category',\n",
    "    }\n",
    "    \n",
    "    # Create new dataframe with standardized columns\n",
    "    df_standardized = pd.DataFrame()\n",
    "    \n",
    "    # Map columns\n",
    "    for old_name, new_name in column_mapping.items():\n",
    "        if old_name in df.columns:\n",
    "            df_standardized[new_name] = df[old_name]\n",
    "    \n",
    "    # Define columns to keep in final output\n",
    "    columns_to_keep = [\n",
    "        'timestamp',\n",
    "        'entry_id',\n",
    "        'temperature',\n",
    "        'turbidity',\n",
    "        'dissolved_oxygen',\n",
    "        'ph',\n",
    "        'ammonia',\n",
    "        'nitrate',\n",
    "        'population',\n",
    "        'fish_length',\n",
    "        'fish_weight',\n",
    "        'water_safety_score',\n",
    "        'safety_category'\n",
    "    ]\n",
    "    \n",
    "    # Keep only columns that exist\n",
    "    final_columns = [col for col in columns_to_keep if col in df_standardized.columns]\n",
    "    df_standardized = df_standardized[final_columns]\n",
    "    \n",
    "    return df_standardized\n",
    "\n",
    "\n",
    "def concatenate_dataframes(df_list):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STANDARDIZING AND CONCATENATING DATAFRAMES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    standardized_dfs = []\n",
    "    \n",
    "    for i, df in enumerate(df_list):\n",
    "        print(f\"\\nProcessing DataFrame {i+1}:\")\n",
    "        print(f\"  Original shape: {df.shape}\")\n",
    "        print(f\"  Original columns: {len(df.columns)}\")\n",
    "        \n",
    "        # Standardize\n",
    "        df_std = standardize_dataframe(df)\n",
    "        \n",
    "        print(f\"  Standardized shape: {df_std.shape}\")\n",
    "        print(f\"  Standardized columns: {list(df_std.columns)}\")\n",
    "        df_std['source_df'] = i + 1\n",
    "        standardized_dfs.append(df_std)\n",
    "    \n",
    "    df_combined = pd.concat(standardized_dfs, axis=0, ignore_index=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CONCATENATION COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Combined shape: {df_combined.shape}\")\n",
    "    print(f\"Total rows: {len(df_combined)}\")\n",
    "    print(f\"Columns: {list(df_combined.columns)}\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nRows per source:\")\n",
    "    print(df_combined['source_df'].value_counts().sort_index())\n",
    "    \n",
    "    print(\"\\nMissing values per column:\")\n",
    "    missing = df_combined.isnull().sum()\n",
    "    missing = missing[missing > 0]\n",
    "    if len(missing) > 0:\n",
    "        for col, count in missing.items():\n",
    "            pct = (count / len(df_combined)) * 100\n",
    "            print(f\"  {col}: {count} ({pct:.2f}%)\")\n",
    "    else:\n",
    "        print(\"  No missing values!\")\n",
    "    \n",
    "    return df_combined\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_dataframes = [df1,df2,df3,df4,df9,df10,df11,df12,df6]\n",
    "    df_combined = concatenate_dataframes(all_dataframes)\n",
    "    df_combined.to_csv('combined_data_part1_with_population.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8664e8d-e442-436b-9ce1-ba39238fc993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STANDARDIZING AND CONCATENATING DATAFRAMES\n",
      "======================================================================\n",
      "\n",
      "Processing DataFrame 1:\n",
      "  Original shape: (70744, 15)\n",
      "  Original columns: 15\n",
      "  Standardized shape: (70744, 12)\n",
      "  Standardized columns: ['timestamp', 'entry_id', 'temperature', 'turbidity', 'dissolved_oxygen', 'ph', 'ammonia', 'nitrate', 'fish_length', 'fish_weight', 'water_safety_score', 'safety_category']\n",
      "\n",
      "Processing DataFrame 2:\n",
      "  Original shape: (70744, 17)\n",
      "  Original columns: 17\n",
      "  Standardized shape: (70744, 12)\n",
      "  Standardized columns: ['timestamp', 'entry_id', 'temperature', 'turbidity', 'dissolved_oxygen', 'ph', 'ammonia', 'nitrate', 'fish_length', 'fish_weight', 'water_safety_score', 'safety_category']\n",
      "\n",
      "======================================================================\n",
      "CONCATENATION COMPLETE\n",
      "======================================================================\n",
      "Combined shape: (141488, 13)\n",
      "Total rows: 141488\n",
      "Columns: ['timestamp', 'entry_id', 'temperature', 'turbidity', 'dissolved_oxygen', 'ph', 'ammonia', 'nitrate', 'fish_length', 'fish_weight', 'water_safety_score', 'safety_category', 'source_df']\n",
      "\n",
      "Rows per source:\n",
      "source_df\n",
      "1    70744\n",
      "2    70744\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values per column:\n",
      "  No missing values!\n"
     ]
    }
   ],
   "source": [
    "#dataframe with population\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_dataframes = [df7,df8]\n",
    "    df_combined2 = concatenate_dataframes(all_dataframes)\n",
    "    df_combined2.to_csv('combined_data_part2_without_population.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75b1e4e4-784e-48e2-b602-d4d15777ea6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 764315 entries, 0 to 764314\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   timestamp           764315 non-null  object \n",
      " 1   entry_id            764315 non-null  float64\n",
      " 2   temperature         764315 non-null  float64\n",
      " 3   turbidity           764315 non-null  float64\n",
      " 4   dissolved_oxygen    764315 non-null  float64\n",
      " 5   ph                  764315 non-null  float64\n",
      " 6   ammonia             764225 non-null  float64\n",
      " 7   nitrate             764315 non-null  float64\n",
      " 8   population          612530 non-null  float64\n",
      " 9   fish_length         764315 non-null  object \n",
      " 10  fish_weight         764315 non-null  float64\n",
      " 11  water_safety_score  764315 non-null  float64\n",
      " 12  safety_category     764315 non-null  object \n",
      " 13  source_df           764315 non-null  int64  \n",
      "dtypes: float64(10), int64(1), object(3)\n",
      "memory usage: 81.6+ MB\n",
      "None\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 141488 entries, 0 to 141487\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   timestamp           141488 non-null  object \n",
      " 1   entry_id            141488 non-null  int64  \n",
      " 2   temperature         141488 non-null  float64\n",
      " 3   turbidity           141488 non-null  int64  \n",
      " 4   dissolved_oxygen    141488 non-null  float64\n",
      " 5   ph                  141488 non-null  float64\n",
      " 6   ammonia             141488 non-null  float64\n",
      " 7   nitrate             141488 non-null  int64  \n",
      " 8   fish_length         141488 non-null  float64\n",
      " 9   fish_weight         141488 non-null  float64\n",
      " 10  water_safety_score  141488 non-null  float64\n",
      " 11  safety_category     141488 non-null  object \n",
      " 12  source_df           141488 non-null  int64  \n",
      "dtypes: float64(7), int64(4), object(2)\n",
      "memory usage: 14.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_combined.info())\n",
    "print(\"\\n\")\n",
    "print(df_combined2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3862a3d3-44a2-476f-91b1-d1d39019c082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CALCULATING FISH HEALTH SCORES (WITHOUT POPULATION)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "FISH HEALTH RANGES (WITHOUT POPULATION)\n",
      "======================================================================\n",
      "Valid records: 141488 / 141488\n",
      "\n",
      "Fish Length: 16.87 | 18.04 | 32.09\n",
      "Fish Weight: 50.53 | 61.11 | 300.20\n",
      "\n",
      "Weights adjusted for missing population data:\n",
      "  - Fish Length: 42%\n",
      "  - Fish Weight: 42%\n",
      "  - Condition Factor: 16%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_fish_length(df):\n",
    "    \"\"\"Convert fish_length to numeric if it's stored as object\"\"\"\n",
    "    if df['fish_length'].dtype == 'object':\n",
    "        df['fish_length'] = pd.to_numeric(df['fish_length'], errors='coerce')\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_fish_health_ranges_without_population(df):\n",
    "    \"\"\"\n",
    "    Calculate health ranges using IQR method - NO population\n",
    "    \"\"\"\n",
    "    df = clean_fish_length(df)\n",
    "    \n",
    "    # Remove rows where fish metrics are missing\n",
    "    df_clean = df.dropna(subset=['fish_length', 'fish_weight'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FISH HEALTH RANGES (WITHOUT POPULATION)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Valid records: {len(df_clean)} / {len(df)}\")\n",
    "    \n",
    "    FISH_HEALTH_RANGES = {}\n",
    "    \n",
    "    # Fish Length (higher is better) - increased weight\n",
    "    data = df_clean['fish_length']\n",
    "    Q1, Q2, Q3 = data.quantile([0.25, 0.50, 0.75])\n",
    "    IQR = Q3 - Q1\n",
    "    FISH_HEALTH_RANGES['fish_length'] = {\n",
    "        'optimal': (Q2, Q3),\n",
    "        'acceptable': (Q1, Q3 + 0.5*IQR),\n",
    "        'critical_low': Q1 - 1.5*IQR,\n",
    "        'critical_high': Q3 + 1.5*IQR,\n",
    "        'weight': 0.42,  # Increased from 0.35\n",
    "        'direction': 'higher_better'\n",
    "    }\n",
    "    print(f\"\\nFish Length: {Q1:.2f} | {Q2:.2f} | {Q3:.2f}\")\n",
    "    \n",
    "    # Fish Weight (higher is better) - increased weight\n",
    "    data = df_clean['fish_weight']\n",
    "    Q1, Q2, Q3 = data.quantile([0.25, 0.50, 0.75])\n",
    "    IQR = Q3 - Q1\n",
    "    FISH_HEALTH_RANGES['fish_weight'] = {\n",
    "        'optimal': (Q2, Q3),\n",
    "        'acceptable': (Q1, Q3 + 0.5*IQR),\n",
    "        'critical_low': Q1 - 1.5*IQR,\n",
    "        'critical_high': Q3 + 1.5*IQR,\n",
    "        'weight': 0.42,  # Increased from 0.35\n",
    "        'direction': 'higher_better'\n",
    "    }\n",
    "    print(f\"Fish Weight: {Q1:.2f} | {Q2:.2f} | {Q3:.2f}\")\n",
    "    \n",
    "    # Condition Factor weight - increased\n",
    "    FISH_HEALTH_RANGES['condition_factor'] = {'weight': 0.16}  # Increased from 0.15\n",
    "    \n",
    "    print(\"\\nWeights adjusted for missing population data:\")\n",
    "    print(\"  - Fish Length: 42%\")\n",
    "    print(\"  - Fish Weight: 42%\")\n",
    "    print(\"  - Condition Factor: 16%\")\n",
    "    \n",
    "    return FISH_HEALTH_RANGES\n",
    "\n",
    "\n",
    "def calculate_condition_factor(df):\n",
    "    \"\"\"Calculate Fulton's Condition Factor: K = (Weight / Length^3) * 100\"\"\"\n",
    "    df = clean_fish_length(df)\n",
    "    \n",
    "    df['condition_factor'] = (df['fish_weight'] / (df['fish_length'] ** 3)) * 100\n",
    "    df['condition_factor'] = df['condition_factor'].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_metric_score(value, param_name, ranges):\n",
    "    \"\"\"Calculate health score (0-100) for a single metric\"\"\"\n",
    "    if param_name not in ranges or pd.isna(value):\n",
    "        return np.nan\n",
    "    \n",
    "    r = ranges[param_name]\n",
    "    opt_low, opt_high = r['optimal']\n",
    "    acc_low, acc_high = r['acceptable']\n",
    "    crit_low = r['critical_low']\n",
    "    crit_high = r['critical_high']\n",
    "    direction = r.get('direction', 'higher_better')\n",
    "    \n",
    "    # Length/Weight: higher is better\n",
    "    if opt_low <= value <= opt_high:\n",
    "        return 100\n",
    "    elif value > opt_high:\n",
    "        return 100 if value <= acc_high else max(90, 100 - 10 * (value - acc_high) / (crit_high - acc_high))\n",
    "    elif value < opt_low:\n",
    "        if value >= acc_low:\n",
    "            return 75 - 25 * (opt_low - value) / (opt_low - acc_low)\n",
    "        elif value >= crit_low:\n",
    "            return 25 + 50 * (value - crit_low) / (acc_low - crit_low)\n",
    "        else:\n",
    "            return 10\n",
    "\n",
    "\n",
    "def score_condition_factor(k):\n",
    "    \"\"\"Score Condition Factor (K)\"\"\"\n",
    "    if pd.isna(k):\n",
    "        return np.nan\n",
    "    if 1.0 <= k <= 1.5:\n",
    "        return 100\n",
    "    elif (0.8 <= k < 1.0) or (1.5 < k <= 2.0):\n",
    "        return 75 + 25 * min((k - 0.8) / 0.2, (2.0 - k) / 0.5) if k < 1.0 else 75 + 25 * (2.0 - k) / 0.5\n",
    "    elif 0.5 <= k < 0.8 or 2.0 < k <= 3.0:\n",
    "        return 25 + 50 * min((k - 0.5) / 0.3, (3.0 - k) / 1.0) if k < 0.8 else 25 + 50 * (3.0 - k) / 1.0\n",
    "    else:\n",
    "        return 10\n",
    "\n",
    "\n",
    "def add_fish_health_scores_without_population(df):\n",
    "    \"\"\"\n",
    "    Add fish health scores to dataframe (NO population)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CALCULATING FISH HEALTH SCORES (WITHOUT POPULATION)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Clean and calculate condition factor\n",
    "    df = clean_fish_length(df)\n",
    "    df = calculate_condition_factor(df)\n",
    "    \n",
    "    # Calculate ranges\n",
    "    FISH_HEALTH_RANGES = calculate_fish_health_ranges_without_population(df)\n",
    "    \n",
    "    # Individual metric scores\n",
    "    df['fish_length_score'] = df['fish_length'].apply(\n",
    "        lambda x: calculate_metric_score(x, 'fish_length', FISH_HEALTH_RANGES)\n",
    "    )\n",
    "    df['fish_weight_score'] = df['fish_weight'].apply(\n",
    "        lambda x: calculate_metric_score(x, 'fish_weight', FISH_HEALTH_RANGES)\n",
    "    )\n",
    "    df['condition_factor_score'] = df['condition_factor'].apply(score_condition_factor)\n",
    "    \n",
    "    # Overall Fish Health Score (adjusted weights without population)\n",
    "    df['fish_health_score'] = (\n",
    "        0.42 * df['fish_length_score'].fillna(0) +\n",
    "        0.42 * df['fish_weight_score'].fillna(0) +\n",
    "        0.16 * df['condition_factor_score'].fillna(0)\n",
    "    )\n",
    "    \n",
    "    # Health Category\n",
    "    def get_health_category(score):\n",
    "        if pd.isna(score):\n",
    "            return 'UNKNOWN'\n",
    "        if score >= 80:\n",
    "            return 'EXCELLENT'\n",
    "        elif score >= 65:\n",
    "            return 'GOOD'\n",
    "        elif score >= 50:\n",
    "            return 'FAIR'\n",
    "        elif score >= 35:\n",
    "            return 'POOR'\n",
    "        else:\n",
    "            return 'CRITICAL'\n",
    "    \n",
    "    df['fish_health_category'] = df['fish_health_score'].apply(get_health_category)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    df = df_combined2.copy()    \n",
    "    df = add_fish_health_scores_without_population(df)\n",
    "    df.to_csv('data_with_fish_health_no_population.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b5c2958-2305-41d9-9a68-ad8e7a8ada8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 141488 entries, 0 to 141487\n",
      "Data columns (total 19 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   timestamp               141488 non-null  object \n",
      " 1   entry_id                141488 non-null  int64  \n",
      " 2   temperature             141488 non-null  float64\n",
      " 3   turbidity               141488 non-null  int64  \n",
      " 4   dissolved_oxygen        141488 non-null  float64\n",
      " 5   ph                      141488 non-null  float64\n",
      " 6   ammonia                 141488 non-null  float64\n",
      " 7   nitrate                 141488 non-null  int64  \n",
      " 8   fish_length             141488 non-null  float64\n",
      " 9   fish_weight             141488 non-null  float64\n",
      " 10  water_safety_score      141488 non-null  float64\n",
      " 11  safety_category         141488 non-null  object \n",
      " 12  source_df               141488 non-null  int64  \n",
      " 13  condition_factor        141488 non-null  float64\n",
      " 14  fish_length_score       141488 non-null  float64\n",
      " 15  fish_weight_score       141488 non-null  float64\n",
      " 16  condition_factor_score  141488 non-null  float64\n",
      " 17  fish_health_score       141488 non-null  float64\n",
      " 18  fish_health_category    141488 non-null  object \n",
      "dtypes: float64(12), int64(4), object(3)\n",
      "memory usage: 20.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7cca89b-e9de-41a8-ad53-0a3ed31e5a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CALCULATING FISH HEALTH SCORES (WITH POPULATION)\n",
      "======================================================================\n",
      "\n",
      "✓ Condition Factor (K) calculated\n",
      "  Mean K: 0.906\n",
      "  Min K: 0.474\n",
      "  Max K: 8.601\n",
      "\n",
      "======================================================================\n",
      "FISH HEALTH RANGES (WITH POPULATION)\n",
      "======================================================================\n",
      "Valid records: 612529 / 764315\n",
      "\n",
      "✓ Fish Length:\n",
      "  Q1: 12.96 | Q2 (median): 17.52 | Q3: 23.42\n",
      "  Optimal: 17.52 - 23.42 cm\n",
      "\n",
      "✓ Fish Weight:\n",
      "  Q1: 18.10 | Q2 (median): 47.20 | Q3: 119.32\n",
      "  Optimal: 47.20 - 119.32 g\n",
      "\n",
      "✓ Population Density:\n",
      "  Q1: 50 | Q2 (median): 50 | Q3: 75\n",
      "  Optimal: 50 - 50 fish (lower = less crowding)\n",
      "\n",
      "======================================================================\n",
      "WEIGHT DISTRIBUTION:\n",
      "  - Fish Length: 35%\n",
      "  - Fish Weight: 35%\n",
      "  - Population: 15%\n",
      "  - Condition Factor: 15%\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "CALCULATING INDIVIDUAL METRIC SCORES\n",
      "======================================================================\n",
      "✓ Fish length score calculated\n",
      "✓ Fish weight score calculated\n",
      "✓ Population score calculated\n",
      "✓ Condition factor score calculated\n",
      "\n",
      "✓ Overall fish health score calculated\n"
     ]
    }
   ],
   "source": [
    "def clean_fish_length(df):\n",
    "    \"\"\"Convert fish_length to numeric if it's stored as object\"\"\"\n",
    "    if df['fish_length'].dtype == 'object':\n",
    "        df['fish_length'] = pd.to_numeric(df['fish_length'], errors='coerce')\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_condition_factor(df):\n",
    "    \"\"\"\n",
    "    Calculate Fulton's Condition Factor (K-factor)\n",
    "    K = (Weight / Length³) × 100\n",
    "    \n",
    "    Healthy range: 1.0 - 1.5\n",
    "    \"\"\"\n",
    "    df = clean_fish_length(df)\n",
    "    \n",
    "    df['condition_factor'] = (df['fish_weight'] / (df['fish_length'] ** 3)) * 100\n",
    "    df['condition_factor'] = df['condition_factor'].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    print(f\"\\n✓ Condition Factor (K) calculated\")\n",
    "    print(f\"  Mean K: {df['condition_factor'].mean():.3f}\")\n",
    "    print(f\"  Min K: {df['condition_factor'].min():.3f}\")\n",
    "    print(f\"  Max K: {df['condition_factor'].max():.3f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_fish_health_ranges_with_population(df):\n",
    "    \"\"\"\n",
    "    Calculate health ranges using IQR method - includes population\n",
    "    \"\"\"\n",
    "    df = clean_fish_length(df)\n",
    "    \n",
    "    # Remove rows where fish metrics are missing\n",
    "    df_clean = df.dropna(subset=['fish_length', 'fish_weight', 'population'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FISH HEALTH RANGES (WITH POPULATION)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Valid records: {len(df_clean)} / {len(df)}\")\n",
    "    \n",
    "    FISH_HEALTH_RANGES = {}\n",
    "    \n",
    "    # Fish Length (higher is better)\n",
    "    data = df_clean['fish_length']\n",
    "    Q1, Q2, Q3 = data.quantile([0.25, 0.50, 0.75])\n",
    "    IQR = Q3 - Q1\n",
    "    FISH_HEALTH_RANGES['fish_length'] = {\n",
    "        'optimal': (Q2, Q3),\n",
    "        'acceptable': (Q1, Q3 + 0.5*IQR),\n",
    "        'critical_low': Q1 - 1.5*IQR,\n",
    "        'critical_high': Q3 + 1.5*IQR,\n",
    "        'weight': 0.35,\n",
    "        'direction': 'higher_better'\n",
    "    }\n",
    "    print(f\"\\n✓ Fish Length:\")\n",
    "    print(f\"  Q1: {Q1:.2f} | Q2 (median): {Q2:.2f} | Q3: {Q3:.2f}\")\n",
    "    print(f\"  Optimal: {Q2:.2f} - {Q3:.2f} cm\")\n",
    "    \n",
    "    # Fish Weight (higher is better)\n",
    "    data = df_clean['fish_weight']\n",
    "    Q1, Q2, Q3 = data.quantile([0.25, 0.50, 0.75])\n",
    "    IQR = Q3 - Q1\n",
    "    FISH_HEALTH_RANGES['fish_weight'] = {\n",
    "        'optimal': (Q2, Q3),\n",
    "        'acceptable': (Q1, Q3 + 0.5*IQR),\n",
    "        'critical_low': Q1 - 1.5*IQR,\n",
    "        'critical_high': Q3 + 1.5*IQR,\n",
    "        'weight': 0.35,\n",
    "        'direction': 'higher_better'\n",
    "    }\n",
    "    print(f\"\\n✓ Fish Weight:\")\n",
    "    print(f\"  Q1: {Q1:.2f} | Q2 (median): {Q2:.2f} | Q3: {Q3:.2f}\")\n",
    "    print(f\"  Optimal: {Q2:.2f} - {Q3:.2f} g\")\n",
    "    \n",
    "    # Population (lower is better - less crowding)\n",
    "    data = df_clean['population']\n",
    "    Q1, Q2, Q3 = data.quantile([0.25, 0.50, 0.75])\n",
    "    IQR = Q3 - Q1\n",
    "    FISH_HEALTH_RANGES['population'] = {\n",
    "        'optimal': (Q1, Q2),  # Lower half is better\n",
    "        'acceptable': (Q1 - 0.5*IQR, Q3),\n",
    "        'critical_low': Q1 - 1.5*IQR,\n",
    "        'critical_high': Q3 + 1.5*IQR,\n",
    "        'weight': 0.15,\n",
    "        'direction': 'lower_better'\n",
    "    }\n",
    "    print(f\"\\n✓ Population Density:\")\n",
    "    print(f\"  Q1: {Q1:.0f} | Q2 (median): {Q2:.0f} | Q3: {Q3:.0f}\")\n",
    "    print(f\"  Optimal: {Q1:.0f} - {Q2:.0f} fish (lower = less crowding)\")\n",
    "    \n",
    "    # Condition Factor weight\n",
    "    FISH_HEALTH_RANGES['condition_factor'] = {'weight': 0.15}\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"WEIGHT DISTRIBUTION:\")\n",
    "    print(\"  - Fish Length: 35%\")\n",
    "    print(\"  - Fish Weight: 35%\")\n",
    "    print(\"  - Population: 15%\")\n",
    "    print(\"  - Condition Factor: 15%\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return FISH_HEALTH_RANGES\n",
    "\n",
    "\n",
    "def calculate_metric_score(value, param_name, ranges):\n",
    "    \"\"\"Calculate health score (0-100) for a single metric\"\"\"\n",
    "    if param_name not in ranges or pd.isna(value):\n",
    "        return np.nan\n",
    "    \n",
    "    r = ranges[param_name]\n",
    "    opt_low, opt_high = r['optimal']\n",
    "    acc_low, acc_high = r['acceptable']\n",
    "    crit_low = r['critical_low']\n",
    "    crit_high = r['critical_high']\n",
    "    direction = r.get('direction', 'higher_better')\n",
    "    \n",
    "    # Population: lower is better (less overcrowding)\n",
    "    if direction == 'lower_better':\n",
    "        if opt_low <= value <= opt_high:\n",
    "            return 100\n",
    "        elif value < opt_low:\n",
    "            return 100 if value >= acc_low else max(50, 75 + 25 * (value - crit_low) / (acc_low - crit_low))\n",
    "        elif value > opt_high:\n",
    "            if value <= acc_high:\n",
    "                return 75 - 25 * (value - opt_high) / (acc_high - opt_high)\n",
    "            elif value <= crit_high:\n",
    "                return 25 + 50 * (crit_high - value) / (crit_high - acc_high)\n",
    "            else:\n",
    "                return 10  # Severe overcrowding\n",
    "    \n",
    "    # Length/Weight: higher is better (good growth)\n",
    "    else:\n",
    "        if opt_low <= value <= opt_high:\n",
    "            return 100\n",
    "        elif value > opt_high:\n",
    "            return 100 if value <= acc_high else max(90, 100 - 10 * (value - acc_high) / (crit_high - acc_high))\n",
    "        elif value < opt_low:\n",
    "            if value >= acc_low:\n",
    "                return 75 - 25 * (opt_low - value) / (opt_low - acc_low)\n",
    "            elif value >= crit_low:\n",
    "                return 25 + 50 * (value - crit_low) / (acc_low - crit_low)\n",
    "            else:\n",
    "                return 10  # Stunted growth\n",
    "    \n",
    "    return 50  # Default fallback\n",
    "\n",
    "\n",
    "def score_condition_factor(k):\n",
    "    \"\"\"\n",
    "    Score Condition Factor (K)\n",
    "    Scoring:\n",
    "    - 100: K between 1.0 and 1.5 (optimal)\n",
    "    - 75-99: K between 0.8-1.0 or 1.5-2.0 (acceptable)\n",
    "    - 25-74: K between 0.5-0.8 or 2.0-3.0 (poor)\n",
    "    - 10: K below 0.5 or above 3.0 (critical)\n",
    "    \"\"\"\n",
    "    if pd.isna(k):\n",
    "        return np.nan\n",
    "    \n",
    "    # Optimal range\n",
    "    if 1.0 <= k <= 1.5:\n",
    "        return 100\n",
    "    \n",
    "    # Acceptable range\n",
    "    elif (0.8 <= k < 1.0):\n",
    "        return 75 + 25 * (k - 0.8) / 0.2\n",
    "    elif (1.5 < k <= 2.0):\n",
    "        return 75 + 25 * (2.0 - k) / 0.5\n",
    "    \n",
    "    # Poor range\n",
    "    elif (0.5 <= k < 0.8):\n",
    "        return 25 + 50 * (k - 0.5) / 0.3\n",
    "    elif (2.0 < k <= 3.0):\n",
    "        return 25 + 50 * (3.0 - k) / 1.0\n",
    "    \n",
    "    # Critical\n",
    "    else:\n",
    "        return 10\n",
    "\n",
    "\n",
    "def add_fish_health_scores_with_population(df):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CALCULATING FISH HEALTH SCORES (WITH POPULATION)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Clean and calculate condition factor\n",
    "    df = clean_fish_length(df)\n",
    "    df = calculate_condition_factor(df)\n",
    "    \n",
    "    # Calculate ranges from data\n",
    "    FISH_HEALTH_RANGES = calculate_fish_health_ranges_with_population(df)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CALCULATING INDIVIDUAL METRIC SCORES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Individual metric scores\n",
    "    df['fish_length_score'] = df['fish_length'].apply(\n",
    "        lambda x: calculate_metric_score(x, 'fish_length', FISH_HEALTH_RANGES)\n",
    "    )\n",
    "    print(\"✓ Fish length score calculated\")\n",
    "    \n",
    "    df['fish_weight_score'] = df['fish_weight'].apply(\n",
    "        lambda x: calculate_metric_score(x, 'fish_weight', FISH_HEALTH_RANGES)\n",
    "    )\n",
    "    print(\"✓ Fish weight score calculated\")\n",
    "    \n",
    "    df['population_score'] = df['population'].apply(\n",
    "        lambda x: calculate_metric_score(x, 'population', FISH_HEALTH_RANGES)\n",
    "    )\n",
    "    print(\"✓ Population score calculated\")\n",
    "    \n",
    "    df['condition_factor_score'] = df['condition_factor'].apply(score_condition_factor)\n",
    "    print(\"✓ Condition factor score calculated\")\n",
    "    \n",
    "    # Overall Fish Health Score (weighted average)\n",
    "    df['fish_health_score'] = (\n",
    "        0.35 * df['fish_length_score'].fillna(0) +\n",
    "        0.35 * df['fish_weight_score'].fillna(0) +\n",
    "        0.15 * df['population_score'].fillna(0) +\n",
    "        0.15 * df['condition_factor_score'].fillna(0)\n",
    "    )\n",
    "    print(\"\\n✓ Overall fish health score calculated\")\n",
    "    \n",
    "    # Fish Health Category\n",
    "    def get_health_category(score):\n",
    "        if pd.isna(score):\n",
    "            return 'UNKNOWN'\n",
    "        if score >= 80:\n",
    "            return 'EXCELLENT'\n",
    "        elif score >= 65:\n",
    "            return 'GOOD'\n",
    "        elif score >= 50:\n",
    "            return 'FAIR'\n",
    "        elif score >= 35:\n",
    "            return 'POOR'\n",
    "        else:\n",
    "            return 'CRITICAL'\n",
    "    \n",
    "    df['fish_health_category'] = df['fish_health_score'].apply(get_health_category)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Load dataframe WITH population\n",
    "    df = df_combined.copy()\n",
    "    df = add_fish_health_scores_with_population(df)\n",
    "    \n",
    "    # Save results\n",
    "    output_file = 'data_with_fish_health_and_population.csv'\n",
    "    df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf62dea3-9d4b-450c-99d1-c18364b006e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 764315 entries, 0 to 764314\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   timestamp               764315 non-null  object \n",
      " 1   entry_id                764315 non-null  float64\n",
      " 2   temperature             764315 non-null  float64\n",
      " 3   turbidity               764315 non-null  float64\n",
      " 4   dissolved_oxygen        764315 non-null  float64\n",
      " 5   ph                      764315 non-null  float64\n",
      " 6   ammonia                 764225 non-null  float64\n",
      " 7   nitrate                 764315 non-null  float64\n",
      " 8   population              612530 non-null  float64\n",
      " 9   fish_length             764314 non-null  float64\n",
      " 10  fish_weight             764315 non-null  float64\n",
      " 11  water_safety_score      764315 non-null  float64\n",
      " 12  safety_category         764315 non-null  object \n",
      " 13  source_df               764315 non-null  int64  \n",
      " 14  condition_factor        764314 non-null  float64\n",
      " 15  fish_length_score       764314 non-null  float64\n",
      " 16  fish_weight_score       764315 non-null  float64\n",
      " 17  population_score        612530 non-null  float64\n",
      " 18  condition_factor_score  764314 non-null  float64\n",
      " 19  fish_health_score       764315 non-null  float64\n",
      " 20  fish_health_category    764315 non-null  object \n",
      "dtypes: float64(17), int64(1), object(3)\n",
      "memory usage: 122.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d979ce65-9aba-4365-8f98-388ed0b45711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
